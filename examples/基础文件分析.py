"""
åŸºç¡€æ–‡ä»¶åˆ†æç¤ºä¾‹

æœ¬ç¤ºä¾‹æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨MDIPæ¥åˆ†æExcelæ–‡ä»¶ç»“æ„å¹¶æå–å­—æ®µä¿¡æ¯ã€‚
"""

import sys
from pathlib import Path

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent / 'src'))

from mdip.core.matcher import DataMatcher
from mdip.core.reporter import ReportGenerator
import pandas as pd


def analyze_single_file(file_path: str):
    """åˆ†æå•ä¸ªExcelæ–‡ä»¶å¹¶æ˜¾ç¤ºç»“æœã€‚"""
    print(f"ğŸ” æ­£åœ¨åˆ†ææ–‡ä»¶: {file_path}")
    
    matcher = DataMatcher()
    
    try:
        # åˆ†ææ–‡ä»¶ç»“æ„
        analysis = matcher.analyze_excel_structure(file_path)
        
        print(f"\nğŸ“Š æ–‡ä»¶åˆ†æç»“æœ:")
        print(f"   ğŸ“ æ–‡ä»¶å: {Path(file_path).name}")
        print(f"   ğŸ“‹ å·¥ä½œè¡¨æ€»æ•°: {len(analysis['sheets'])}")
        print(f"   ğŸ·ï¸  å­—æ®µæ€»æ•°: {analysis['total_fields']}")
        
        # æ˜¾ç¤ºå·¥ä½œè¡¨ä¿¡æ¯
        print(f"\nğŸ“‘ å·¥ä½œè¡¨è¯¦æƒ…:")
        for sheet_name, sheet_info in analysis['sheets'].items():
            print(f"   å·¥ä½œè¡¨: {sheet_name}")
            print(f"     å­—æ®µæ•°: {len(sheet_info['headers'])}")
            print(f"     ç¤ºä¾‹å­—æ®µ: {', '.join(sheet_info['headers'][:5])}")
            if len(sheet_info['headers']) > 5:
                print(f"     ... è¿˜æœ‰ {len(sheet_info['headers']) - 5} ä¸ªå­—æ®µ")
            print()
        
        return analysis
    
    except Exception as e:
        print(f"âŒ åˆ†ææ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
        return None


def analyze_directory(directory_path: str):
    """åˆ†æç›®å½•ä¸­çš„æ‰€æœ‰Excelæ–‡ä»¶ã€‚"""
    print(f"ğŸ” æ­£åœ¨åˆ†æç›®å½•: {directory_path}")
    
    matcher = DataMatcher()
    
    # å‘ç°æ–‡ä»¶
    file_registry = matcher.discover_excel_files(directory_path)
    
    if not file_registry:
        print("âŒ ç›®å½•ä¸­æœªæ‰¾åˆ°Excelæ–‡ä»¶ã€‚")
        return
    
    print(f"ğŸ“Š æ‰¾åˆ° {len(file_registry)} ä¸ªExcelæ–‡ä»¶:")
    
    all_analyses = {}
    
    for file_path, file_info in file_registry.items():
        print(f"\nğŸ“„ æ­£åœ¨å¤„ç†: {file_info['filename']}")
        
        analysis = analyze_single_file(file_path)
        if analysis:
            all_analyses[file_path] = analysis
    
    # ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
    if all_analyses:
        generate_summary_report(all_analyses)
    
    return all_analyses


def generate_summary_report(analyses: dict):
    """ä»å¤šä¸ªæ–‡ä»¶åˆ†æç»“æœç”Ÿæˆæ±‡æ€»æŠ¥å‘Šã€‚"""
    print(f"\nğŸ“ ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š")
    print("=" * 50)
    
    total_files = len(analyses)
    total_sheets = sum(len(analysis['sheets']) for analysis in analyses.values())
    total_fields = sum(analysis['total_fields'] for analysis in analyses.values())
    
    print(f"ğŸ“Š æ±‡æ€»ç»Ÿè®¡:")
    print(f"   åˆ†ææ–‡ä»¶æ•°: {total_files}")
    print(f"   å·¥ä½œè¡¨æ€»æ•°: {total_sheets}")
    print(f"   å­—æ®µæ€»æ•°: {total_fields}")
    print(f"   å¹³å‡æ¯æ–‡ä»¶å­—æ®µæ•°: {total_fields / total_files:.1f}")
    
    # å­—æ®µé¢‘ç‡åˆ†æ
    field_counts = {}
    for analysis in analyses.values():
        for sheet_info in analysis['sheets'].values():
            for field in sheet_info['headers']:
                field_lower = field.lower().strip()
                field_counts[field_lower] = field_counts.get(field_lower, 0) + 1
    
    # æœ€å¸¸è§å­—æ®µ
    common_fields = sorted(field_counts.items(), key=lambda x: x[1], reverse=True)[:10]
    
    print(f"\nğŸ”¥ æœ€å¸¸è§å­—æ®µ (å‰10ä¸ª):")
    for field, count in common_fields:
        print(f"   {field}: {count} æ¬¡å‡ºç°")
    
    # ç”ŸæˆExcelæŠ¥å‘Š
    reporter = ReportGenerator()
    
    # å‡†å¤‡æŠ¥å‘Šæ•°æ®
    dataframes = {}
    for file_path, analysis in analyses.items():
        filename = Path(file_path).stem
        
        # åˆ›å»ºå·¥ä½œè¡¨æ±‡æ€»
        sheet_data = []
        for sheet_name, sheet_info in analysis['sheets'].items():
            sheet_data.append({
                'æ–‡ä»¶å': filename,
                'å·¥ä½œè¡¨': sheet_name,
                'å­—æ®µæ•°': len(sheet_info['headers']),
                'ç¤ºä¾‹å­—æ®µ': ', '.join(sheet_info['headers'][:3])
            })
        
        if sheet_data:
            dataframes[filename] = pd.DataFrame(sheet_data)
    
    # ç”Ÿæˆå¹¶å¯¼å‡ºæŠ¥å‘Š
    report = reporter.generate_data_summary_report(dataframes, "æ–‡ä»¶åˆ†ææ±‡æ€»æŠ¥å‘Š")
    
    output_file = "æ–‡ä»¶åˆ†ææŠ¥å‘Š.xlsx"
    reporter.export_report_to_excel(report, output_file)
    
    print(f"\nâœ… è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜è‡³: {output_file}")


def main():
    """ç¤ºä¾‹ä¸»å‡½æ•°ã€‚"""
    print("ğŸ¥ åŒ»ç–—æ•°æ®æ•´åˆå¹³å° - æ–‡ä»¶åˆ†æç¤ºä¾‹")
    print("=" * 60)
    
    if len(sys.argv) < 2:
        print("ä½¿ç”¨æ–¹æ³•: python åŸºç¡€æ–‡ä»¶åˆ†æ.py <æ–‡ä»¶æˆ–ç›®å½•è·¯å¾„>")
        print("\nç¤ºä¾‹:")
        print("  python åŸºç¡€æ–‡ä»¶åˆ†æ.py æ•°æ®.xlsx")
        print("  python åŸºç¡€æ–‡ä»¶åˆ†æ.py /path/to/data/directory")
        sys.exit(1)
    
    input_path = sys.argv[1]
    
    if not Path(input_path).exists():
        print(f"âŒ è·¯å¾„ä¸å­˜åœ¨: {input_path}")
        sys.exit(1)
    
    # æ£€æŸ¥è¾“å…¥æ˜¯æ–‡ä»¶è¿˜æ˜¯ç›®å½•
    if Path(input_path).is_file():
        # å•æ–‡ä»¶åˆ†æ
        if input_path.endswith(('.xlsx', '.xls')):
            analysis = analyze_single_file(input_path)
            if analysis:
                print("\nâœ… æ–‡ä»¶åˆ†æå®Œæˆã€‚")
        else:
            print("âŒ æ–‡ä»¶å¿…é¡»æ˜¯Excelæ ¼å¼ (.xlsx æˆ– .xls)")
    
    elif Path(input_path).is_dir():
        # ç›®å½•åˆ†æ
        analyses = analyze_directory(input_path)
        if analyses:
            print(f"\nâœ… ç›®å½•åˆ†æå®Œæˆã€‚å¤„ç†äº† {len(analyses)} ä¸ªæ–‡ä»¶ã€‚")
    
    else:
        print("âŒ è¾“å…¥å¿…é¡»æ˜¯æ–‡ä»¶æˆ–ç›®å½•")


if __name__ == "__main__":
    main()