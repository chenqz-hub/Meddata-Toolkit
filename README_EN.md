# Medical Data Integration Platform (MDIP)

A comprehensive, professional-grade platform for integrating, analyzing, and ensuring quality of medical research data from multiple sources. Built with software engineering best practices for clinical research environments.

## ğŸ¯ Features

- **ğŸ“Š Multi-format Support**: Excel (.xlsx, .xls), CSV file processing
- **ğŸ” Data Quality Assessment**: Comprehensive quality metrics and reporting (completeness, accuracy, consistency, uniqueness, timeliness)
- **ğŸ”— Flexible Matching**: Exact and fuzzy matching algorithms with configurable thresholds
- **âš™ï¸ Field Configuration**: Customizable field definitions and categories for medical data
- **âœ… Validation Framework**: Built-in medical data validation rules and custom rule support
- **ğŸ“ˆ Advanced Reporting**: Detailed reports in Excel and JSON formats with visualizations
- **ğŸ’» CLI Interface**: Professional command-line tools for automation and batch processing
- **ğŸ¥ Medical Data Focus**: Specialized tools for clinical research data integration

## ğŸš€ Quick Start

### Method 1: Direct CLI Usage (Recommended)

```bash
# Analyze file structure in a directory
mdip analyze ./data --output analysis_report.xlsx --verbose

# Assess data quality with medical validation rules
mdip quality patients.xlsx --medical --critical-fields patient_id,name --output quality_report.xlsx

# Match data from multiple files with fuzzy matching
mdip match cag_data.xlsx pci_data.csv --fields patient_id,name --fuzzy --output integration_report.xlsx

# Validate data against medical standards
mdip validate lab_results.xlsx --medical --show-errors --output validation_report.xlsx
```

### Method 2: Installation and Library Usage

```bash
# Install MDIP as a package
pip install -r requirements.txt
pip install -e .

# Use as Python library
python -c "from mdip.core.matcher import DataMatcher; print('MDIP installed successfully!')"
```

## ğŸ“‹ Installation

### Prerequisites
- Python 3.8 or higher
- pip package manager

### Install Dependencies

```bash
# Navigate to the project directory
cd "D:\\git\\Meddata-Toolkit"

# Install runtime dependencies
pip install -r requirements-runtime.txt

# Optional: install dev dependencies
pip install -r requirements.txt

# Optional: Install in development mode for library usage
pip install -e .
```

### Verify Installation

```bash
# Test CLI functionality
mdip --help

# Test with sample data (if available)
python examples/basic_file_analysis.py ./
```

## ğŸ› ï¸ Usage Examples

### 1. File Structure Analysis

```bash
# Analyze all Excel files in a directory
mdip analyze ./medical_data --output structure_analysis.xlsx --show-fields

# Analyze with verbose output to see detailed field information
mdip analyze ./data --verbose --output detailed_analysis.xlsx
```

### 2. Data Quality Assessment

```bash
# Basic quality assessment
mdip quality patient_data.xlsx --output quality_report.xlsx

# Medical data quality assessment with critical fields
mdip quality clinical_data.xlsx --medical \
  --critical-fields patient_id,medical_record_number \
  --important-fields age,gender,diagnosis \
  --key-fields patient_id \
  --output comprehensive_quality_report.xlsx

# Quality assessment with specific Excel sheet
mdip quality workbook.xlsx --sheet "Patient Demographics" --output quality_report.json
```

### 3. Data Matching and Integration

```bash
# Basic exact matching
mdip match file1.xlsx file2.csv --fields patient_id --output match_results.xlsx

# Advanced fuzzy matching for names and IDs
mdip match cag_patients.xlsx pci_patients.xlsx \
  --fields patient_id,patient_name,medical_record_number \
  --fuzzy --output patient_integration.xlsx

# Multi-file integration with custom configuration
mdip match data1.xlsx data2.xlsx data3.csv \
  --fields id,name --fuzzy --config custom_match_config.json \
  --output multi_source_integration.xlsx
```

### 4. Data Validation

```bash
# Medical data validation with built-in rules
mdip validate patient_records.xlsx --medical --output validation_results.xlsx

# General validation with error details
mdip validate lab_data.csv --show-errors --verbose --output detailed_validation.xlsx

# Custom validation rules (when implemented)
mdip validate research_data.xlsx --rules custom_rules.json --output validation_report.xlsx
```

## ğŸ—ï¸ Project Structure

```
Meddata-Toolkit/
â”œâ”€â”€ ğŸ“„ requirements-runtime.txt   # Runtime dependencies
â”œâ”€â”€ ğŸ“„ requirements.txt           # Dev/extra dependencies
â”œâ”€â”€ ğŸ“„ setup.py                   # Package installation configuration
â”œâ”€â”€ ğŸ“„ README.md                  # This documentation
â”œâ”€â”€ ğŸ“‚ src/mdip/                  # Main MDIP package
â”‚   â”œâ”€â”€ ğŸ“‚ core/                  # Core functionality modules
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ matcher.py         # Data matching and integration engine
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ quality_control.py # Comprehensive quality assessment
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ validation.py      # Data validation framework
â”‚   â”‚   â””â”€â”€ ğŸ“„ reporter.py        # Advanced reporting and export
â”‚   â”œâ”€â”€ ğŸ“‚ config/                # Configuration management
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ field_config.py    # Medical field definitions and categories
â”‚   â”‚   â””â”€â”€ ğŸ“„ match_config.py    # Matching algorithm configuration
â”‚   â”œâ”€â”€ ğŸ“‚ utils/                 # Utility functions and helpers
â”‚   â”‚   â””â”€â”€ ğŸ“„ data_utils.py      # Data processing and transformation
â”‚   â””â”€â”€ ğŸ“‚ cli/                   # Command-line interface
â”‚       â””â”€â”€ ğŸ“„ main.py            # CLI implementation and commands
â”œâ”€â”€ ğŸ“‚ tests/                     # Comprehensive test suite
â”‚   â”œâ”€â”€ ğŸ“„ conftest.py            # Test configuration and fixtures
â”‚   â”œâ”€â”€ ğŸ“„ test_matcher.py        # Data matching tests
â”‚   â””â”€â”€ ğŸ“„ test_quality_control.py # Quality assessment tests
â”œâ”€â”€ ğŸ“‚ examples/                  # Usage examples and tutorials
â”‚   â”œâ”€â”€ ğŸ“„ README.md              # Examples documentation
â”‚   â”œâ”€â”€ ğŸ“„ basic_file_analysis.py # File analysis example
â”‚   â””â”€â”€ ğŸ“„ quality_assessment_demo.py # Quality assessment demo
â”œâ”€â”€ ğŸ“‚ docs/                      # Additional documentation
â””â”€â”€ ğŸ“‚ scripts/                   # Utility and maintenance scripts
```

## ğŸ§© Core Components

### DataMatcher (`src/mdip/core/matcher.py`)
- **File Discovery**: Automatically discovers and catalogs Excel and CSV files
- **Structure Analysis**: Extracts sheet names, field names, and basic statistics
- **Multi-format Loading**: Handles Excel (multiple sheets) and CSV files
- **Intelligent Matching**: Exact and fuzzy matching with configurable similarity thresholds
- **Integration Engine**: Merges data from multiple sources with quality tracking

### QualityAssessment (`src/mdip/core/quality_control.py`)
- **5-Dimension Analysis**: Completeness, Accuracy, Consistency, Uniqueness, Timeliness
- **Field-Level Metrics**: Individual field quality scores and recommendations
- **Critical Field Support**: Prioritized assessment for essential medical fields
- **Automated Grading**: A-F quality grades with improvement recommendations
- **Historical Tracking**: Quality trend analysis and monitoring

### ValidationFramework (`src/mdip/core/validation.py`)
- **Medical Rule Library**: Built-in validation for medical data (age ranges, lab values, etc.)
- **Custom Rule Engine**: Extensible validation rule framework
- **Batch Validation**: Efficient processing of large datasets
- **Detailed Reporting**: Row-level and field-level error reporting
- **Real-time Checks**: Integration with data loading pipeline

### ReportingSystem (`src/mdip/core/reporter.py`)
- **Multi-format Export**: Excel workbooks with multiple sheets, JSON for APIs
- **Executive Summaries**: High-level quality and integration reports
- **Detailed Analytics**: Field-by-field analysis and recommendations
- **Visual Elements**: Progress bars, quality grades, and trend indicators
- **Automated Insights**: Intelligent recommendations based on data patterns

## âš™ï¸ Configuration and Customization

### Medical Field Configuration

```python
from mdip.config.field_config import FieldConfig

# Create custom field configuration
config = FieldConfig()

# Add medical field categories
config.add_field_group("patient_identifiers", [
    "patient_id", "medical_record_number", "study_id"
])

config.add_field_group("demographics", [
    "age", "gender", "date_of_birth", "ethnicity"
])

config.add_field_group("clinical_measurements", [
    "blood_pressure_systolic", "blood_pressure_diastolic", 
    "heart_rate", "weight", "height", "bmi"
])

# Set field priorities
config.set_field_priority("patient_id", "critical")
config.set_field_priority("medical_record_number", "critical")
config.set_field_priority("age", "important")
```

### Matching Algorithm Configuration

```python
from mdip.config.match_config import MatchConfig

# Configure matching behavior
config = MatchConfig()

# Exact match fields (must match exactly)
config.exact_match_fields = ["patient_id", "medical_record_number"]

# Fuzzy match fields (allow similarity matching)
config.fuzzy_match_fields = ["patient_name", "doctor_name"]

# Similarity thresholds
config.fuzzy_threshold = 0.85  # 85% similarity required
config.name_similarity_threshold = 0.9  # Higher threshold for names

# Matching weights for confidence calculation
config.field_weights = {
    "patient_id": 0.4,
    "medical_record_number": 0.3,
    "patient_name": 0.2,
    "date_of_birth": 0.1
}
```

## ğŸ“Š Report Examples

### Quality Assessment Report Structure

```
ğŸ“ˆ QUALITY ASSESSMENT RESULTS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ¯ Overall Quality Score: 0.847 (Grade: B)

ğŸ“Š Quality Dimensions:
  Completeness  0.892 [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] A
  Consistency   0.834 [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ ] B  
  Uniqueness    0.978 [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] A
  Accuracy      0.756 [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     ] C
  Timeliness    0.823 [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] B

ğŸ” Key Findings:
  âš ï¸  Found 23 duplicate rows (2.3%)
  âš ï¸  Found 156 data accuracy issues
  
ğŸ“‹ Field Completeness (lowest 5):
  diagnosis            67.4% (326 missing) [C]
  secondary_diagnosis  45.2% (548 missing) [F]
  follow_up_date      89.1% (109 missing) [B]
  lab_result_date     92.3% (77 missing)  [A]
  notes               34.7% (653 missing) [F]

ğŸ’¡ Recommendations:
  1. Improve data completeness through better data collection processes
  2. Implement deduplication procedures to reduce duplicate records
  3. Add validation rules and data entry checks to improve accuracy
```

### Integration Report Structure

```
ğŸ”— DATA INTEGRATION REPORT
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š Integration Summary:
  Source Datasets: 3
  Total Records Processed: 2,847
  Successful Matches: 2,234 (78.5%)
  Failed Matches: 613 (21.5%)
  Final Quality Score: 0.823

ğŸ¯ Matching Results by Source:
  CAG_patients.xlsx â†’ PCI_patients.xlsx: 1,456 matches (94.2%)
  Lab_results.csv â†’ Patient_data.xlsx: 778 matches (67.8%)

ğŸ“ˆ Confidence Distribution:
  High Confidence (â‰¥90%): 1,567 matches (70.1%)
  Medium Confidence (70-89%): 534 matches (23.9%)
  Low Confidence (<70%): 133 matches (6.0%)
```

## ğŸ§ª Testing

### Running Tests

```bash
# Run all tests
python -m pytest tests/ -v

# Run specific test modules
python -m pytest tests/test_matcher.py -v
python -m pytest tests/test_quality_control.py -v

# Run with coverage report
python -m pytest tests/ --cov=mdip --cov-report=html

# Run tests for specific functionality
python -m pytest tests/ -k "test_quality" -v
```

### Test Coverage Areas

- **Unit Tests**: Individual component functionality
- **Integration Tests**: End-to-end workflow testing
- **Performance Tests**: Large dataset handling
- **Error Handling**: Edge cases and error conditions
- **Configuration Tests**: Custom configuration scenarios

## ğŸ”§ Development and Extensions

### Adding Custom Validation Rules

```python
from mdip.core.validation import ValidationRule, DataValidator

class CustomLabValueRule(ValidationRule):
    def __init__(self, min_val, max_val, test_name):
        super().__init__(f"{test_name}_range", f"{test_name} must be between {min_val} and {max_val}")
        self.min_val = min_val
        self.max_val = max_val
    
    def validate(self, data):
        if pd.isna(data):
            return True, ""
        
        try:
            value = float(data)
            if self.min_val <= value <= self.max_val:
                return True, ""
            else:
                return False, f"Value {value} is outside normal range ({self.min_val}-{self.max_val})"
        except (ValueError, TypeError):
            return False, f"Invalid numeric value: {data}"

# Use custom rule
validator = DataValidator()
validator.add_rule("hemoglobin", CustomLabValueRule(8.0, 18.0, "Hemoglobin"))
```

### Extending Field Configurations

```python
from mdip.config.field_config import FieldConfig

class CardiacFieldConfig(FieldConfig):
    def __init__(self):
        super().__init__()
        self._setup_cardiac_fields()
    
    def _setup_cardiac_fields(self):
        # Define cardiac-specific field categories
        self.add_field_group("cardiac_procedures", [
            "pci_date", "stent_type", "vessel_treated", "lesion_location"
        ])
        
        self.add_field_group("cardiac_measurements", [
            "ejection_fraction", "troponin", "ck_mb", "nt_probnp"
        ])
        
        # Set validation rules
        self.add_validation_rule("ejection_fraction", "range", min=15, max=80)
        self.add_validation_rule("pci_date", "date_format", format="%Y-%m-%d")
```

## ğŸ†˜ Troubleshooting

### Common Issues and Solutions

**Issue**: `ModuleNotFoundError: No module named 'mdip'`
```bash
# Solution: Install dependencies and package
pip install -r requirements.txt
pip install -e .
```

**Issue**: `Permission denied` when writing reports
```bash
# Solution: Check file permissions and close Excel if open
# Use a different output directory with write permissions
mdip quality data.xlsx --output ./reports/quality_report.xlsx
```

**Issue**: `UnicodeDecodeError` when processing files
```bash
# Solution: Ensure files are in UTF-8 encoding
# Or specify encoding in CSV files (feature to be added)
```

**Issue**: Poor matching results
```bash
# Solution: Adjust fuzzy matching threshold or add more matching fields
mdip match file1.xlsx file2.xlsx \
  --fields patient_id,name,dob \
  --fuzzy --verbose
```

## ğŸ“ Support and Contributing

### Getting Help

1. **Check Documentation**: Review this README and examples
2. **Run with `--verbose`**: Get detailed execution information
3. **Check Log Files**: Look for `mdip.log` in the project directory
4. **Open GitHub Issue**: Provide sample data and error details

### Contributing Guidelines

1. **Fork the Repository**: Create your own copy for development
2. **Create Feature Branch**: `git checkout -b feature/new-functionality`
3. **Follow Code Style**: Use consistent formatting and documentation
4. **Add Tests**: Include tests for new functionality
5. **Update Documentation**: Update README and docstrings
6. **Submit Pull Request**: Include detailed description of changes

### Development Setup

```bash
# Clone and setup development environment
git clone <repository-url>
cd Meddata-Toolkit
pip install -r requirements-runtime.txt
pip install -r requirements.txt
pip install -e .

# Install development dependencies
pip install pytest pytest-cov black flake8

# Run development checks
black src/  # Format code
flake8 src/  # Check style
pytest tests/ --cov=mdip  # Run tests with coverage
```

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ™ Acknowledgments

- Built for medical research data integration needs
- Designed with clinical research workflows in mind  
- Follows software engineering best practices for reliability
- Supports FAIR (Findable, Accessible, Interoperable, Reusable) data principles